{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46e8a66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing customConv2d.py\n"
     ]
    }
   ],
   "source": [
    "%%file customConv2d.py\n",
    "#Подключение модулей\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def customConv2d(in_channels, out_channels, kernel_size, stride=1, padding=0\\\n",
    "    , dilation=1, groups=1, bias=True, padding_mode=\"zeros\"):\n",
    "    #Обёртка\n",
    "    def wrapper(mat):\n",
    "        #Проверки параметров\n",
    "        if (in_channels%groups !=0) or (out_channels%groups !=0):\n",
    "            raise Exception(f\"%s must be divisible by groups\" % (\"in_channels\" if in_channels%groups !=0 else \"out_channels\"))\n",
    "        if padding < 0:\n",
    "            raise Exception(f\"Padiing should be 0 or positive\")\n",
    "        if stride < 0:\n",
    "            raise Exception(f\"Stride should be 0 or positive\")\n",
    "        if groups < 0:\n",
    "            raise Exception(f\"Groups should be positive\")  \n",
    "        \n",
    "        #Смещение\n",
    "        if bias:\n",
    "            bias_value = torch.rand(out_channels)\n",
    "        else:\n",
    "            bias_value = torch.zeros(out_channels)\n",
    "        \n",
    "        #Подложка\n",
    "        if (padding_mode == 'zeros'):\n",
    "            pad = torch.nn.ZeroPad2d(padding)\n",
    "            mat = pad(mat)\n",
    "        elif (padding_mode == 'reflect'):\n",
    "            pad = torch.nn.ReflectionPad2d(padding)\n",
    "            mat = pad(mat)\n",
    "        elif (padding_mode == 'replicate'):\n",
    "            pad = torch.nn.ReplicationPad2d(padding)\n",
    "            mat = pad(mat)\n",
    "        elif (padding_mode == 'circular'):\n",
    "            pad = torch.nn.CircularPad2d(padding)\n",
    "            mat = pad(mat)\n",
    "        else:\n",
    "            raise Exception(f\"Ivalid padding_mode\")\n",
    "        \n",
    "        #Фильтр с учётом размера ядра\n",
    "        if type(kernel_size) == tuple:\n",
    "            flter = torch.rand(out_channels, in_channels//groups, kernel_size[0],kernel_size[1])\n",
    "        elif type(kernel_size) == int:\n",
    "            flter = torch.rand(out_channels, in_channels//groups, kernel_size,kernel_size)\n",
    "        else:\n",
    "            raise Exception(f\"Ivalid kernel_size type\")\n",
    "            \n",
    "        #\"Обход\" фильтром\n",
    "        res = []\n",
    "        for chnl in range(out_channels):\n",
    "            feature_map = np.array([])\n",
    "            for i in range(0, mat.shape[1] - ((flter.shape[2]- 1) * dilation + 1) + 1, stride):\n",
    "                for j in range(0, mat.shape[2] - ((flter.shape[3]- 1) * dilation + 1) + 1, stride):\n",
    "                    total = 0\n",
    "                    for k in range(in_channels // groups):\n",
    "                        if groups > 1:\n",
    "                            cur = mat[chnl * (in_channels // groups) + k]\\\n",
    "                            [i:i + (flter.shape[2] - 1) * dilation + 1 : dilation,\\\n",
    "                             j:j + + (flter.shape[3] - 1) * dilation + 1 : dilation]\n",
    "                        else:\n",
    "                            cur = mat[k]\\\n",
    "                            [i:i + (flter.shape[2] - 1) * dilation + 1 : dilation,\\\n",
    "                             j:j + + (flter.shape[3] - 1) * dilation + 1 : dilation]\n",
    "                        total += (cur * flter[chnl][k]).sum()\n",
    "                    feature_map = np.append(feature_map, float(total + bias_value[chnl]))\n",
    "            res.append(feature_map.reshape((mat.shape[1] - ((flter.shape[2] - 1) * dilation + 1)) // stride + 1,\\\n",
    "                          (mat.shape[2] - ((flter.shape[3] - 1) * dilation + 1)) // stride + 1))\n",
    "        return np.array(res), np.array(flter), np.array(bias_value)\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "186994f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing test_scenario1.py\n"
     ]
    }
   ],
   "source": [
    "%%file test_scenario1.py\n",
    "from customConv2d import customConv2d\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "test_data_1 = torch.rand(3,28,28)\n",
    "test_data_2 = torch.rand(4,5,6)\n",
    "test_data_3 = torch.rand(1,1,1)\n",
    "\n",
    "\n",
    "def test1():\n",
    "    customConv = customConv2d(in_channels=3, out_channels=1, kernel_size=3, stride=1, padding=0\\\n",
    "    , dilation=2, groups=1, bias=True, padding_mode=\"zeros\")\n",
    "    result, flter, bias_value = customConv(test_data_1)\n",
    "    torchConv = torch.nn.Conv2d(in_channels=3,out_channels=1, kernel_size=3, stride=1, padding=0\\\n",
    "    , dilation=2, groups=1, bias=True, padding_mode=\"zeros\")\n",
    "    torchConv.weight.data = torch.tensor(flter)\n",
    "    torchConv.bias.data = torch.tensor(bias_value)\n",
    "    customResult = str(np.round(result,2))\n",
    "    torchResult = str(np.round(np.array(torchConv(test_data_1).data),2))\n",
    "    assert customResult == torchResult\n",
    "\n",
    "def test2():\n",
    "    customConv = customConv2d(in_channels=4, out_channels=2, kernel_size=3, stride=1, padding=0\\\n",
    "    , dilation=1, groups=2, bias=True, padding_mode=\"zeros\")\n",
    "    result, flter, bias_value = customConv(test_data_2)\n",
    "    torchConv = torch.nn.Conv2d(in_channels=4,out_channels=2, kernel_size=3, stride=1, padding=0\\\n",
    "    , dilation=1, groups=2, bias=True, padding_mode=\"zeros\")\n",
    "    torchConv.weight.data = torch.tensor(flter)\n",
    "    torchConv.bias.data = torch.tensor(bias_value)\n",
    "    customResult = str(np.round(result,2))\n",
    "    torchResult = str(np.round(np.array(torchConv(test_data_2).data),2))\n",
    "    assert customResult == torchResult\n",
    "    \n",
    "def test3():\n",
    "    customConv = customConv2d(in_channels=1, out_channels=1, kernel_size=1, stride=1, padding=0\\\n",
    "    , dilation=1, groups=1, bias=True, padding_mode=\"zeros\")\n",
    "    result, flter, bias_value = customConv(test_data_3)\n",
    "    torchConv = torch.nn.Conv2d(in_channels=1,out_channels=1, kernel_size=1, stride=1, padding=0\\\n",
    "    , dilation=1, groups=1, bias=True, padding_mode=\"zeros\")\n",
    "    torchConv.weight.data = torch.tensor(flter)\n",
    "    torchConv.bias.data = torch.tensor(bias_value)\n",
    "    customResult = str(np.round(result,2))\n",
    "    torchResult = str(np.round(np.array(torchConv(test_data_3).data),2))\n",
    "    assert customResult == torchResult\n",
    "    \n",
    "test1()\n",
    "test2()\n",
    "test3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "630ff565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[5.04730415 5.18026257 4.93953371 4.39059877]\n",
      "  [4.46178722 4.75485706 4.75369453 4.85265064]\n",
      "  [4.91872978 5.42088318 5.08985996 5.30127621]]\n",
      "\n",
      " [[4.761621   5.21794558 4.48905706 4.80508327]\n",
      "  [5.92620373 4.43653202 5.27439308 4.50783825]\n",
      "  [4.73047829 5.60497427 3.72169018 5.04763317]]\n",
      "\n",
      " [[3.01267719 4.08773613 4.1187191  3.94151878]\n",
      "  [4.16531992 4.6256156  4.04231548 4.66406202]\n",
      "  [3.87949991 5.08908415 4.24431038 3.89047098]]\n",
      "\n",
      " [[4.904109   5.49715328 5.80218029 5.80726528]\n",
      "  [4.64712048 5.72986794 5.9329567  6.22966957]\n",
      "  [5.34495354 5.15145588 5.88048267 6.2201128 ]]]\n",
      "-------------------------------------------------\n",
      "[[[5.047304  5.1802626 4.9395337 4.390599 ]\n",
      "  [4.461787  4.754857  4.7536945 4.8526506]\n",
      "  [4.91873   5.420883  5.08986   5.3012753]]\n",
      "\n",
      " [[4.7616205 5.2179456 4.4890566 4.8050838]\n",
      "  [5.926204  4.436532  5.274393  4.507838 ]\n",
      "  [4.7304783 5.604974  3.7216902 5.047633 ]]\n",
      "\n",
      " [[3.0126772 4.087736  4.1187196 3.9415188]\n",
      "  [4.16532   4.625615  4.042315  4.6640615]\n",
      "  [3.8795    5.0890837 4.244311  3.890472 ]]\n",
      "\n",
      " [[4.904109  5.4971533 5.8021803 5.8072653]\n",
      "  [4.6471205 5.729868  5.9329567 6.2296696]\n",
      "  [5.3449535 5.151456  5.8804836 6.220113 ]]]\n"
     ]
    }
   ],
   "source": [
    "from customConv2d import customConv2d\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "test_example = torch.rand(8, 5, 6)\n",
    "\n",
    "customConv = customConv2d(in_channels=8, out_channels=4, kernel_size=3, stride=1, padding=0\\\n",
    "    , dilation=1, groups=4, bias=True, padding_mode=\"zeros\")\n",
    "result, flter, bias_value = customConv(test_example)\n",
    "torchConv = torch.nn.Conv2d(in_channels=8,out_channels=4, kernel_size=3, stride=1, padding=0\\\n",
    ", dilation=1, groups=4, bias=True, padding_mode=\"zeros\")\n",
    "torchConv.weight.data = torch.tensor(flter)\n",
    "torchConv.bias.data = torch.tensor(bias_value)\n",
    "\n",
    "print(result)\n",
    "print(\"-------------------------------------------------\")\n",
    "print(np.array(torchConv(test_example).data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
